Spark Standalone Mode
预部署的模式是：A（10.131.120.233）、B两台服务器、A为master，A、B为worker
具体步骤
1、下载spark1.2.1 release版本，http://spark.apache.org/downloads.html
  下载预编译的版本spark-1.2.1-bin-hadoop2.4.tgz，省去了编译的麻烦
2、tar -zxf spark-1.2.1-bin-hadoop2.4.tgz解压到部署目录下，本人使用的是work账号，解压到/home/work/目录下
3、修改./conf/spark-env.sh
JAVA_HOME=/usr/local/jdk
export SPARK_MASTER_IP=10.131.120.233(master服务器)
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1
export SPARK_MASTER_PORT=7777（master端口）
export SPARK_WORKER_MEMORY=2g

4、启动master节点
./sbin/start-master.sh
启动本机的worker节点
./bin/spark-class org.apache.spark.deploy.worker.Worker spark://10.131.120.233:7777

5、可以通过一台服务器控制整个cluster的停止与启动。
vim ./conf/slaves
添加
A（ip/host）
B (ip/host)

6、把slaves和spark-env.sh文件复制到B服务器
7、然后需要B和A建立 无密码登录ssh的信任关系。（具体操作见我的ssh no password文章）
8、配置完以后即可通过A机器./sbin/start-master.sh启动master节点
./sbin/start-slaves.sh来启动所有worker节点
